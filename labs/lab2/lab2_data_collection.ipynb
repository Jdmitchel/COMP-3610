{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Collection\n",
    "In this lab we will take a quick look at some simple data collection and preprocessing techniques."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "554f7df9d1b6afa1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Collection\n",
    "\n",
    "Ever thought about grabbing some cool data for your project? Sure, you could just download a ready-made dataset that fits your needs. But let's be real - sometimes, what you need is as unique as a unicorn in a field of horses.\n",
    "\n",
    "So, what do you do when the perfect dataset is playing hard to get? You have two awesome choices:\n",
    "\n",
    "1. **Become a Data Detective with APIs**: Think of an API as your personal data assistant. It's like saying, \"Hey API, can you fetch me some data?\" And voila, it gets the job done.\n",
    "\n",
    "2. **DIY Dataset Creation**: Roll up your sleeves and create your dataset masterpiece. How? By using techniques like web scraping or crawling for example. It's like going on a treasure hunt on the internet!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c78e319b7a833a46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### API\n",
    "Use “**The Movie DB**” API to:\n",
    "    1. Download data about movies.\n",
    "    2. Search for movies in the “Comedy” genre released in the year 2000 or later. Retrieve the 300 most popular movies in this genre. The movies should be sorted from most popular to least popular. Hint: Sorting based on popularity can be done in the API call.\n",
    "    3. For each comedy movie, download its first 5 similar movies. If a movie has fewer than 5 similar movies, the API will return as many as it can find. Your code should be flexible to work with however many movies the API returns.\n",
    "    \n",
    "For more information on retrieving movie data, visit the following The Movie DB API documentation pages:\n",
    "        - [Movie Discover](https://developers.themoviedb.org/3/discover/movie-discover)\n",
    "        - [Get Movie List](https://developers.themoviedb.org/3/genres/get-movie-list)\n",
    "        - [Get Similar Movies](ttps://developers.themoviedb.org/3/movies/get-similar-movies)\n",
    "\n",
    "#### Saving Results\n",
    "   - **File Format**: For the comedy movies, save the results in `movie_ID_name.csv`. For the comedy movies similar movies, save the results in `movie_ID_sim_movie_ID.csv`.\n",
    "   - **Format Specification**: For the comedy movies, each line should describe one movie in the format `movie-ID,movie-name` without any spaces after the comma and no column headers.\n",
    "   - **Example**: A line in the file could look like `353486,Jumanji: Welcome to the Jungle`.\n",
    "   For the comedy movies' similar movies each line in the file should describe one pair of similar movies in the format `movie-ID,similar-movie-ID`, without any spaces after comma, and no column headers.\n",
    "      - **Example**: If `Jumanji: Welcome to the Jungle` which has ID, `353486` has 3 similar movies with IDs `A`, `B` and `C` respectively then the following lines should be added to `movie_ID_sim_movie_ID.csv`\n",
    "            - `353486, A`\n",
    "            - `353486, B`\n",
    "            - `353486, C`\n",
    "\n",
    "#### Notes\n",
    "   - **Multiple API Calls**: You may need to make multiple calls to retrieve all 300 movies, possibly retrieving them page by page due to pagination.\n",
    "   - **API Parameters**: Use the `primary_release_date` parameter for movies released in 2000 or later, instead of `release_date` to avoid incorrect returns.\n",
    "\n",
    "#### Deliverables\n",
    "   - **movie_ID_name.csv**: The text file that contains the output for 2.\n",
    "   - **movie_ID_sim_movie_ID.csv**: The text file that contains the output for 3.\n",
    "\n",
    "\n",
    "You will need an API key to get data from the TMDb. For the purposes of this lab we will simply include it in our notebook however you should **NOT** do this for anything other than personal projects saved locally. Best practice is to have the API key be inserted at runtime via a command line argument, environment variable etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16d080f56ec2560a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### How to Use TheMovieDB API\n",
    "- **Create an Account**: Sign up at [https://www.themoviedb.org/account/signup](https://www.themoviedb.org/account/signup).\n",
    "- **Request API Key**:\n",
    "  1. Log in and go to **Settings**.\n",
    "  2. Navigate to the **API** tab in the left panel.\n",
    "  3. Request an API key by selecting “Developer” and accepting the terms.\n",
    "  4. Fill out the form.\n",
    "  5. Your API key will be available under the API tab.\n",
    "\n",
    "##### Important Notes\n",
    "- **API Documentation**: Refer to [TheMovieDB API Documentation](https://developers.themoviedb.org/3/getting-started/introduction) for guidance.\n",
    "- **Rate Limiting**: The API allows 40 requests every 10 seconds. Set appropriate timeout intervals in your code.\n",
    "- **Variable Results**: The API may return different results for the same request. Plan your script's run time accordingly.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1457c66f09142c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# !pip install requests beautifulsoup4 python-csv\n",
    "import requests\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T16:18:06.908427300Z",
     "start_time": "2024-01-29T16:18:06.895918600Z"
    }
   },
   "id": "8b78783d27f643",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "api_key = 'ab73f48a6ebf1919888d446764488d4b' # Replace 'YOUR_API_KEY' with your actual API key\n",
    "base_url = 'https://api.themoviedb.org/3'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T16:18:06.924465Z",
     "start_time": "2024-01-29T16:18:06.913828300Z"
    }
   },
   "id": "d5d38491084d4cea",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to get comedy movies\n",
    "def get_comedy_movies():\n",
    "    movies = []\n",
    "    for page in range(1, 13):  # Adjust the range based on how many movies you need\n",
    "        url = f\"{base_url}/discover/movie?api_key={api_key}&with_genres=35&primary_release_date.gte=2000&sort_by=popularity.desc&page={page}\"\n",
    "        response = requests.get(url)\n",
    "        movies.extend(response.json()['results'])\n",
    "        if len(movies) >= 300:\n",
    "            break\n",
    "    return movies[:300]\n",
    "\n",
    "# Function to get similar movies\n",
    "def get_similar_movies(movie_id):\n",
    "    url = f\"{base_url}/movie/{movie_id}/similar?api_key={api_key}&language=en-US&page=1\"\n",
    "    response = requests.get(url)\n",
    "    similar_movies = response.json()['results'][:5]\n",
    "    return similar_movies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T16:18:06.925465200Z",
     "start_time": "2024-01-29T16:18:06.920818400Z"
    }
   },
   "id": "7c62519801808c6",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch and save comedy movies\n",
    "comedy_movies = get_comedy_movies()\n",
    "with open('movie_ID_name.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for movie in comedy_movies:\n",
    "        writer.writerow([movie['id'], movie['title']])\n",
    "        \n",
    "# Fetch and save similar movies for each comedy movie\n",
    "with open('movie_ID_sim_movie_ID.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for movie in comedy_movies:\n",
    "        similar_movies = get_similar_movies(movie['id'])\n",
    "        for sim_movie in similar_movies:\n",
    "            writer.writerow([movie['id'], sim_movie['id']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T16:18:18.360777900Z",
     "start_time": "2024-01-29T16:18:06.928465200Z"
    }
   },
   "id": "58af19281c20fe13",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Web Scraping\n",
    "\n",
    "- **Target Website**: Our goal is to scrape job listings and their details from [Fake Jobs](https://realpython.github.io/fake-jobs/).\n",
    "- **Initial Step**: Start by opening the website in your browser to familiarize yourself with its layout and content.\n",
    "- **Understanding HTML Structure**:\n",
    "  - In Chrome, to understand the page's HTML structure, go to: \n",
    "    - `Options` -> `More Tools` -> `Developer Tools`.\n",
    "  - This will help in planning our scraping strategy effectively.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4748a434d03baa7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we set up our web scraping environment by importing necessary libraries and defining the URL of the website we want to scrape."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e873105b07add1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T16:18:18.366751100Z"
    }
   },
   "id": "33ba131f86e5919a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the main container that holds the job listings on the webpage."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a875d8fb187b560"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = soup.find(id=\"ResultsContainer\")\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T16:18:18.372784100Z",
     "start_time": "2024-01-29T16:18:18.370789700Z"
    }
   },
   "id": "b491175d2a83cfdd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve all job elements/cards from the results container."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1f0d29d47ab9787"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "job_elements = results.find_all(\"div\", class_=\"card-content\")\n",
    "job_elements"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T16:18:18.373755600Z"
    }
   },
   "id": "7403fa9485825738",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the job elements to understand their structure. This includes the job title, company, location, and date/time information."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "241b85a5d7c7f2b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for job_element in job_elements:\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    datetime_element = job_element.find(\"p\", class_=\"is-small has-text-grey\")\n",
    "    print(title_element)\n",
    "    print(\"\\n\")\n",
    "    print(company_element)\n",
    "    print(\"\\n\")\n",
    "    print(location_element)\n",
    "    print(\"\\n\")\n",
    "    print(datetime_element)\n",
    "    print(\"\\n\")\n",
    "    print(\"=====================\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T16:18:18.376782Z"
    }
   },
   "id": "7889552fda56eb23",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the extracted data and then use this function to print the cleaned job details."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b81f689749a08de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_and_strip_text(element):\n",
    "    return element.text.strip()\n",
    "\n",
    "jobs = []\n",
    "for job_element in job_elements:\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    datetime_element = job_element.find(\"p\", class_=\"is-small has-text-grey\")\n",
    "    job = {\"title\": extract_and_strip_text(title_element),\n",
    "            \"company\": extract_and_strip_text(company_element),\n",
    "            \"location\": extract_and_strip_text(location_element),\n",
    "            \"datetime\": extract_and_strip_text(datetime_element)\n",
    "           }\n",
    "    jobs.append(job)\n",
    "    print(job)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# save jobs to csv file\n",
    "with open('fake_jobs.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for job in jobs:\n",
    "        writer.writerow([job['title'], job['company'], job['location'], job['datetime']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T16:18:18.379775Z"
    }
   },
   "id": "16c59b7278abe932",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T16:18:18.383752500Z"
    }
   },
   "id": "b2fefc9f04f18733"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
